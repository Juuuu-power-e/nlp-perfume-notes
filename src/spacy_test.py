import spacy
import numpy as np
from sentence_transformers import SentenceTransformer, util

# 1. ì‚¬ì „ í•™ìŠµëœ ë¬¸ì¥ ì„ë² ë”© ëª¨ë¸
model = SentenceTransformer("all-mpnet-base-v2")

# 2. spaCy ì˜ì–´ ëª¨ë¸ ë¡œë”©
nlp = spacy.load("en_core_web_sm")

# 3. ì˜ˆì‹œ: í…ŒìŠ¤íŠ¸í•  ì„¤ëª… ë¬¸ì¥
test_sentence = "Warm and woody with a hint of spice"

# 4. ì˜ë¯¸ ë‹¨ìœ„ ì¶”ì¶œ í•¨ìˆ˜ (ë‹¨ì–´ or chunk ê¸°ë°˜)
def extract_chunks(sentence):
    doc = nlp(sentence)
    chunks = []

    # ëª…ì‚¬êµ¬, í˜•ìš©ì‚¬ ë“± ì¶”ì¶œ
    for chunk in doc.noun_chunks:
        chunks.append(chunk.text)

    # ì¶”ê°€ë¡œ í˜•ìš©ì‚¬ë„ ë‹¨ë… ì¶”ì¶œ
    for token in doc:
        if token.pos_ == "ADJ":
            if token.text not in chunks:
                chunks.append(token.text)

    return list(set(chunks))  # ì¤‘ë³µ ì œê±°

# 5. ì˜ë¯¸ ë‹¨ìœ„ ì¶”ì¶œ
chunks = extract_chunks(test_sentence)
print("âœ… ì˜ë¯¸ ë‹¨ìœ„:", chunks)

# 6. ìœ ì‚¬ ë¬¸ì¥ í›„ë³´êµ° (ê¸°ì¡´ ì „ì²´ ì„¤ëª… ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸)
# ì˜ˆì‹œìš©. ì‹¤ì œë¡œëŠ” 62ê°œ ì„¤ëª… ì „ì²´ê°€ ì—¬ê¸° ìˆì–´ì•¼ í•¨
corpus = [
    "A cozy and warm scent with amber and vanilla",
    "Fruity citrus blend that feels fresh",
    "Earthy and woody tones with moss and vetiver",
    "Sweet floral notes with jasmine and rose",
    "Spicy cardamom with a smoky finish",
    "Fresh and aquatic with a clean musk base",
]

corpus_embeddings = model.encode(corpus, convert_to_tensor=True)

# 7. ê° chunkë§ˆë‹¤ ìœ ì‚¬ ë¬¸ì¥ ì°¾ê¸°
for chunk in chunks:
    chunk_embedding = model.encode(chunk, convert_to_tensor=True)
    hits = util.semantic_search(chunk_embedding, corpus_embeddings, top_k=3)[0]
    print(f"\nğŸ” '{chunk}' ì™€ ìœ ì‚¬í•œ ì„¤ëª… ë¬¸ì¥:")
    for hit in hits:
        score = hit['score']
        text = corpus[hit['corpus_id']]
        print(f" - ({score:.3f}) {text}")
